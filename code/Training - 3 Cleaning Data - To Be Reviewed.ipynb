{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While in an ideal world, we could jump right into analyze the data, often the data that we receive is not always in a condition to be actually usable. So now that we dealt with the missing data, let us actually look to see if there is any unclean data aka data that doesn't seem to make any sense. \n",
    "\n",
    "The goal at the end of this notebook is to end up with dataset that is clean and ready for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Data + Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that at the beginning of each notebook, there is a code section for importing libraries. Libraries are reusable chucks of code also known as modules. When installing python, there is a standard library which comes with it. For more information about the Standard Library, see https://docs.python.org/3/library/.\n",
    "\n",
    "However, there are some very well known libraries that are extremely useful for data wrangling and analyiss that we have used and continue to use. One of the most used library is pandas (for more imformation about pandas, see https://pandas.pydata.org/). Typically, for these non-prepackaged libraries, we need to install them and import them. The former is done for you, but in each notebook we need to reimport each library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the data a few times. We will leave it up to you. The dataset is stored in a csv called complete_data.csv. The folder structure to the file is [to be filled]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise \n",
    "\n",
    "filepath = None\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "filepath = r'C:\\Users\\jpau\\Documents\\Projects\\Airforce\\data\\complete_data.csv'\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common things that trip up people is duplicate data. Thus, this is generally one of the first things to check for. Let's see if this dataset has duplicates and if there are then let us find out how many duplicates there are. \n",
    "\n",
    "We can do this using the duplicated() method. Why don't you give it a try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "index = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>call_sign</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>KLGA</td>\n",
       "      <td>AAL1850</td>\n",
       "      <td>2020-02-08 13:06:07</td>\n",
       "      <td>off</td>\n",
       "      <td>KLGA</td>\n",
       "      <td>TXKF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>KSLC</td>\n",
       "      <td>DAL642</td>\n",
       "      <td>2020-02-11 01:39:06</td>\n",
       "      <td>on</td>\n",
       "      <td>MMMX</td>\n",
       "      <td>KSLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>KCLT</td>\n",
       "      <td>AAL793</td>\n",
       "      <td>2020-07-30 18:29:18</td>\n",
       "      <td>on</td>\n",
       "      <td>KPHL</td>\n",
       "      <td>KCLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>KIAH</td>\n",
       "      <td>UAL2355</td>\n",
       "      <td>2020-01-13 02:33:34</td>\n",
       "      <td>on</td>\n",
       "      <td>KPHX</td>\n",
       "      <td>KIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14609</th>\n",
       "      <td>KDFW</td>\n",
       "      <td>AAL706</td>\n",
       "      <td>2020-02-13 20:50:10</td>\n",
       "      <td>off</td>\n",
       "      <td>KDFW</td>\n",
       "      <td>KDEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airport call_sign                 time event departure_airport  \\\n",
       "1257     KLGA   AAL1850  2020-02-08 13:06:07   off              KLGA   \n",
       "7105     KSLC    DAL642  2020-02-11 01:39:06    on              MMMX   \n",
       "7686     KCLT    AAL793  2020-07-30 18:29:18    on              KPHL   \n",
       "11915    KIAH   UAL2355  2020-01-13 02:33:34    on              KPHX   \n",
       "14609    KDFW    AAL706  2020-02-13 20:50:10   off              KDFW   \n",
       "\n",
       "      destination_airport  \n",
       "1257                 TXKF  \n",
       "7105                 KSLC  \n",
       "7686                 KCLT  \n",
       "11915                KIAH  \n",
       "14609                KDEN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "\n",
    "index = df.duplicated()\n",
    "\n",
    "df[index].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of duplicates is None\n"
     ]
    }
   ],
   "source": [
    "# Exercise\n",
    "\n",
    "count_of_dups = None\n",
    "\n",
    "print('The count of duplicates is', count_of_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of duplicates is 61775\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "\n",
    "count_of_dups = df.duplicated().sum()\n",
    "\n",
    "print('The count of duplicates is', count_of_dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so there are a good amount of duplicates in our data. Let's remove them. We can do this is the drop_duplicates() method. Why don't you give it a try? Hint: the syntax is similar to the duplicated() and isnull() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "dedup_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "\n",
    "dedup_df = df.drop_duplicates()\n",
    "\n",
    "dedup_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed the duplicates, lets move on to check if we have the right time frame of the data. We know that the data is supposed to be from 1-1-2020 to 9-1-2020. Let's check if this is actually the case.\n",
    "\n",
    "Let's subset the data and see if there there are any observations that are before 1-1-2020 or after 9-1-2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "index = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>call_sign</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KORD</td>\n",
       "      <td>AAL1438</td>\n",
       "      <td>2019-01-28 14:42:30</td>\n",
       "      <td>off</td>\n",
       "      <td>KORD</td>\n",
       "      <td>KMIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>AAL1769</td>\n",
       "      <td>2019-06-22 23:23:59</td>\n",
       "      <td>on</td>\n",
       "      <td>KDFW</td>\n",
       "      <td>KLAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KDFW</td>\n",
       "      <td>AAL1064</td>\n",
       "      <td>2019-03-10 21:27:10</td>\n",
       "      <td>on</td>\n",
       "      <td>KSAN</td>\n",
       "      <td>KDFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KBOS</td>\n",
       "      <td>UAL599</td>\n",
       "      <td>2019-02-26 18:25:58</td>\n",
       "      <td>on</td>\n",
       "      <td>KDEN</td>\n",
       "      <td>KBOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KLAS</td>\n",
       "      <td>AAL777</td>\n",
       "      <td>2019-05-19 20:18:46</td>\n",
       "      <td>off</td>\n",
       "      <td>KLAS</td>\n",
       "      <td>KPHX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978538</th>\n",
       "      <td>KHOU</td>\n",
       "      <td>SWA2891</td>\n",
       "      <td>2019-02-24 05:40:44</td>\n",
       "      <td>on</td>\n",
       "      <td>KMCO</td>\n",
       "      <td>KHOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978539</th>\n",
       "      <td>KDFW</td>\n",
       "      <td>AAL2014</td>\n",
       "      <td>2019-03-03 22:25:28</td>\n",
       "      <td>off</td>\n",
       "      <td>KDFW</td>\n",
       "      <td>KPHX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978543</th>\n",
       "      <td>KBWI</td>\n",
       "      <td>SWA1109</td>\n",
       "      <td>2019-08-15 01:11:44</td>\n",
       "      <td>off</td>\n",
       "      <td>KBWI</td>\n",
       "      <td>KTPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978547</th>\n",
       "      <td>KDCA</td>\n",
       "      <td>AAL798</td>\n",
       "      <td>2019-05-29 11:07:50</td>\n",
       "      <td>off</td>\n",
       "      <td>KDCA</td>\n",
       "      <td>KCLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978550</th>\n",
       "      <td>KFLL</td>\n",
       "      <td>UAL480</td>\n",
       "      <td>2019-03-26 01:57:49</td>\n",
       "      <td>on</td>\n",
       "      <td>KIAH</td>\n",
       "      <td>KFLL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        airport call_sign                 time event departure_airport  \\\n",
       "1          KORD   AAL1438  2019-01-28 14:42:30   off              KORD   \n",
       "11         KLAX   AAL1769  2019-06-22 23:23:59    on              KDFW   \n",
       "13         KDFW   AAL1064  2019-03-10 21:27:10    on              KSAN   \n",
       "18         KBOS    UAL599  2019-02-26 18:25:58    on              KDEN   \n",
       "20         KLAS    AAL777  2019-05-19 20:18:46   off              KLAS   \n",
       "...         ...       ...                  ...   ...               ...   \n",
       "1978538    KHOU   SWA2891  2019-02-24 05:40:44    on              KMCO   \n",
       "1978539    KDFW   AAL2014  2019-03-03 22:25:28   off              KDFW   \n",
       "1978543    KBWI   SWA1109  2019-08-15 01:11:44   off              KBWI   \n",
       "1978547    KDCA    AAL798  2019-05-29 11:07:50   off              KDCA   \n",
       "1978550    KFLL    UAL480  2019-03-26 01:57:49    on              KIAH   \n",
       "\n",
       "        destination_airport  \n",
       "1                      KMIA  \n",
       "11                     KLAX  \n",
       "13                     KDFW  \n",
       "18                     KBOS  \n",
       "20                     KPHX  \n",
       "...                     ...  \n",
       "1978538                KHOU  \n",
       "1978539                KPHX  \n",
       "1978543                KTPA  \n",
       "1978547                KCLT  \n",
       "1978550                KFLL  \n",
       "\n",
       "[534274 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "index = dedup_df['time'] < '2020-01-01'\n",
    "dedup_df[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that there are some events that occur before 1/1/20. Though them being before having this data in this dataset isn't necessarily a problem, for consistency's sake, we will remove this data so that our dataset matches with what was given to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "index = None \n",
    "new_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "index = dedup_df['time'] >= '2020-01-01'\n",
    "timed_df = dedup_df[index].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that is typical in that there might random inappropriate values for your categorical data. Categorical data is data that only involves a limited or fixed number of possible values. One example of a categorical variable might be the airport column. In the airport column, we know that there should only be airports and each of these airports should only have a 4 letter identifier. So let's take a closer look at this column of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KMIA', 'KMEM', 'KDFW', 'KHOU', 'KATL', 'KLAX', 'KSTL', 'KCLT',\n",
       "       'KORD', 'KMDW', 'KDTW', 'KLAS', 'KBOS', 'KSAN', 'KIAH', 'KPHX',\n",
       "       'KJFK', 'KDCA', 'KSEA', 'KEWR', 'KLGA', 'KSLC', 'KBWI', 'KFLL',\n",
       "       'KDEN', 'KPHL', 'KMSP', 'KMCO', 'KSNA', 'KIAD', 'KMKE', 'KSDF',\n",
       "       'KBDL', 'kiah', 'klax', 'ksea', 'kmdw', 'kclt', 'katl', 'kdtw',\n",
       "       'kdfw', 'kphx', 'kiad', 'kbos', 'kphl', 'kord', 'kfll', 'khou',\n",
       "       'KPVD', 'kslc', 'kbwi', 'kden', 'kdca', 'ksan'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timed_df['airport'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things that we see is that there are a bunch of upper case values and a bunch of lower case values. While in some cases this might be okay because these values might indicate different things, in our case, they should actually refer to the same airports. While this might not seem like a big difference, as we analyze this data and group in different ways, this might introduce some unexpected behaviors. So let's fix this. \n",
    "\n",
    "This can be done with the upper() method. You'll notice that I have to put a .str before my method. This is because upper() is a string method and to access the string menthod we need the str attribute. Other methods such as dates (.dt) require this as well. We will explore this more in depth at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timed_df['airport'] = timed_df['airport'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's move on to actually check if take of and landing events actually match up to the destination and departure airports. \n",
    "\n",
    "So from the data it seems that the airport column should be the same as the departure or destination airport columns depending on whether it is a take off or landing. However there are some exceptions. There are cases in which this is not the case. \n",
    "\n",
    "eg. for a takeoff, the reporting airport should be the departure airport (and visa-versa). However, we see that there are a number of cases in which this is not the case. It may be an bad sensor or a mistake in reporting. In either case, let's look at these cases and decide what to do with them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>call_sign</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>KDEN</td>\n",
       "      <td>UAL254</td>\n",
       "      <td>2020-01-01 00:25:02</td>\n",
       "      <td>off</td>\n",
       "      <td>KPHX</td>\n",
       "      <td>KDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>KBWI</td>\n",
       "      <td>SWA4628</td>\n",
       "      <td>2020-01-01 14:39:57</td>\n",
       "      <td>off</td>\n",
       "      <td>KMSY</td>\n",
       "      <td>KBWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6790</th>\n",
       "      <td>KDEN</td>\n",
       "      <td>SWA1424</td>\n",
       "      <td>2020-01-01 16:42:10</td>\n",
       "      <td>off</td>\n",
       "      <td>KGEG</td>\n",
       "      <td>KDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>KIAH</td>\n",
       "      <td>UAL1781</td>\n",
       "      <td>2020-01-02 14:08:51</td>\n",
       "      <td>off</td>\n",
       "      <td>KMAF</td>\n",
       "      <td>KIAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27419</th>\n",
       "      <td>KDEN</td>\n",
       "      <td>UAL2464</td>\n",
       "      <td>2020-01-02 22:40:05</td>\n",
       "      <td>off</td>\n",
       "      <td>KSEA</td>\n",
       "      <td>KDEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airport call_sign                 time event departure_airport  \\\n",
       "344      KDEN    UAL254  2020-01-01 00:25:02   off              KPHX   \n",
       "5047     KBWI   SWA4628  2020-01-01 14:39:57   off              KMSY   \n",
       "6790     KDEN   SWA1424  2020-01-01 16:42:10   off              KGEG   \n",
       "19732    KIAH   UAL1781  2020-01-02 14:08:51   off              KMAF   \n",
       "27419    KDEN   UAL2464  2020-01-02 22:40:05   off              KSEA   \n",
       "\n",
       "      destination_airport  \n",
       "344                  KDEN  \n",
       "5047                 KBWI  \n",
       "6790                 KDEN  \n",
       "19732                KIAH  \n",
       "27419                KDEN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = (timed_df['destination_airport'] == timed_df['airport']) & (timed_df['destination_airport'] != timed_df['departure_airport']) & (timed_df['event'] == 'off')\n",
    "timed_df[index][['airport','call_sign','time','event','departure_airport','destination_airport']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple things to note from the code above. The first is that in order to only look at a portion of the columns, we subsetted the data with a double brackets. This subsets only the columns that are listed. Secondly, you'll notice that conditional statement that we assign to the index is a bit more complicated this time. Effectively, there are three parts to it. The first is does the destination airport match the airport column. The second is that the departure and destination airports do not match. Lastly, that the event is a takeoff.\n",
    "\n",
    "So we found all the takeoffs that didn't seem right. Can we do this for all the landing as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Here\n",
    "\n",
    "index = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport</th>\n",
       "      <th>call_sign</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "      <th>departure_airport</th>\n",
       "      <th>destination_airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>UAL1227</td>\n",
       "      <td>2020-01-01 00:12:55</td>\n",
       "      <td>on</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>PHLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>UAL1227</td>\n",
       "      <td>2020-01-01 00:15:05</td>\n",
       "      <td>on</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>PHLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>UAL1227</td>\n",
       "      <td>2020-01-01 00:18:58</td>\n",
       "      <td>on</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>PHLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>KORD</td>\n",
       "      <td>AAL2517</td>\n",
       "      <td>2020-01-01 00:44:44</td>\n",
       "      <td>on</td>\n",
       "      <td>KORD</td>\n",
       "      <td>MMPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>KPHX</td>\n",
       "      <td>SWA6086</td>\n",
       "      <td>2020-01-01 02:30:22</td>\n",
       "      <td>on</td>\n",
       "      <td>KPHX</td>\n",
       "      <td>KMCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airport call_sign                 time event departure_airport  \\\n",
       "193     KLAX   UAL1227  2020-01-01 00:12:55    on              KLAX   \n",
       "224     KLAX   UAL1227  2020-01-01 00:15:05    on              KLAX   \n",
       "278     KLAX   UAL1227  2020-01-01 00:18:58    on              KLAX   \n",
       "613     KORD   AAL2517  2020-01-01 00:44:44    on              KORD   \n",
       "1890    KPHX   SWA6086  2020-01-01 02:30:22    on              KPHX   \n",
       "\n",
       "     destination_airport  \n",
       "193                 PHLI  \n",
       "224                 PHLI  \n",
       "278                 PHLI  \n",
       "613                 MMPR  \n",
       "1890                KMCI  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "index = (timed_df['departure_airport'] == timed_df['airport']) & (timed_df['event'] == 'on') & (timed_df['destination_airport'] != timed_df['departure_airport'])\n",
    "timed_df[index][['airport','call_sign','time','event','departure_airport','destination_airport']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspection, we see that there only a small number of cases compared to the total amount of cases, so let's drop them because we don't have any additional information regarding them. Why don't you give it a try? Hint: You might need an the bitwise operator for or (|) when making your conditional statement to subset the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "index = None\n",
    "clean_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "index = ((timed_df['destination_airport'] == timed_df['airport']) & (timed_df['event'] == 'on')) | ((timed_df['departure_airport'] == timed_df['airport']) & (timed_df['event'] == 'off'))\n",
    "clean_df = timed_df[index].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have finished cleaning the data, we can finally get around to exploring it and seeing what interesting things we can learn!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Used only for building Scripts\n",
    "clean_df.to_csv(r'C:\\Users\\jpau\\Documents\\Projects\\Airforce\\data\\clean_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
